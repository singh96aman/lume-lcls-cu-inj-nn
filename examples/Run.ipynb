{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0aeb04c",
   "metadata": {},
   "source": [
    "# LUME-services demo\n",
    "In this notebook, we will configure LUME-services to use the service configuration used to launch our docker-compose services. Make sure you've completed all steps outlined in https://slaclab.github.io/lume-services/demo/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b0cfe6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)  # Lets check the logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cb7294",
   "metadata": {},
   "source": [
    "## Configure services\n",
    "LUME-services is packages with a configuration utility that reads environment variables and initializes services:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c1e88af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lume_services.config:Configuring LUME-services environment...\n",
      "INFO:lume_services.config:Environment configured.\n"
     ]
    }
   ],
   "source": [
    "from lume_services import config\n",
    "config.configure()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14910cc",
   "metadata": {},
   "source": [
    "## if you're running this many time, creation will fail because of uniqueness... You can reset since this is a dev server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1dae5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_db_service._reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4ba844",
   "metadata": {},
   "source": [
    "## Create a model\n",
    "The LUME-services Model provides an API to all model services and facilitates all model operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "299e5321",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lume_services.services.models.db.db:ModelDB selecting: SELECT model.model_id, model.created, model.author, model.laboratory, model.facility, model.beampath, model.description \n",
      "FROM model \n",
      "WHERE model.author = :author_1 AND model.laboratory = :laboratory_1 AND model.facility = :facility_1 AND model.beampath = :beampath_1 AND model.description = :description_1\n",
      "INFO:lume_services.services.models.db.db:ModelDB inserting: INSERT INTO model (author, laboratory, facility, beampath, description) VALUES (:author, :laboratory, :facility, :beampath, :description)\n",
      "INFO:lume_services.services.models.db.db:Sucessfully executed: INSERT INTO model (author, laboratory, facility, beampath, description) VALUES (:author, :laboratory, :facility, :beampath, :description)\n",
      "INFO:lume_services.services.models.db.db:ModelDB selecting: SELECT model.model_id, model.created, model.author, model.laboratory, model.facility, model.beampath, model.description \n",
      "FROM model \n",
      "WHERE model.model_id = :model_id_1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(metadata=Model(                     model_id=1,                     created=datetime.datetime(2023, 8, 1, 0, 47, 35),                     author='Aman Singh Thakur'),                     laboratory='slac',                     facility='lcls',                     beampath='cu',                     description='lcls-cu-inj-nn'                 ), deployment=None, results=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lume_services.models import Model\n",
    "\n",
    "model = Model.create_model(\n",
    "    author = \"Aman Singh Thakur\",\n",
    "    laboratory = \"slac\",\n",
    "    facility = \"lcls\",\n",
    "    beampath = \"cu\",\n",
    "    description = \"lcls-cu-inj-nn\"\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3088ad03",
   "metadata": {},
   "source": [
    "## Create a project\n",
    "Workflows are organized by the Prefect scheduler into different projects. Below, we access the configured services directly (TODO create project registry utility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b7a075b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_db_service = config.context.model_db_service()\n",
    "scheduling_service = config.context.scheduling_service()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3c31d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "### NOTE: The below cell will raise an error if run 2x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcd2f83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lume_services.services.models.db.db:ModelDB inserting: INSERT INTO project (project_name, description) VALUES (:project_name, :description)\n",
      "INFO:lume_services.services.models.db.db:Sucessfully executed: INSERT INTO project (project_name, description) VALUES (:project_name, :description)\n"
     ]
    }
   ],
   "source": [
    "# create a project\n",
    "project_name = model_db_service.store_project(\n",
    "    project_name=\"gpu-box-new\", description=\"my_description\"\n",
    ")\n",
    "scheduling_service.create_project(\"gpu-box-new\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abbe01a",
   "metadata": {},
   "source": [
    "You can now find this project in you Prefect UI at http://localhost:8080\n",
    "\n",
    "\n",
    "![project](https://slaclab.github.io/lume-services/files/project_nav.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc23acff",
   "metadata": {},
   "source": [
    "## Create a deployment for your model\n",
    "Replace `source_path` with the path to your release tarball below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2346c829",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lume_services.models.model:installing package\n",
      "INFO:lume_services.environment.solver:https://github.com/singh96aman/lume-lcls-cu-inj-nn/releases/download/v0.0.20/lume_lcls_cu_inj_nn-0.0.20.tar.gz saved to /tmp/tmpib6nu23h/lume_lcls_cu_inj_nn-0.0.20.tar.gz\n",
      "INFO:lume_services.environment.solver:Uninstall complete\n",
      "INFO:lume_services.environment.solver:Installing dependencies...\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.1.0\n",
      "  latest version: 23.7.2\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c conda-forge conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=23.7.2\n",
      "\n",
      "\n",
      "INFO:lume_services.environment.solver:Dependency installation complete\n",
      "INFO:lume_services.environment.solver:https://github.com/singh96aman/lume-lcls-cu-inj-nn/releases/download/v0.0.20/lume_lcls_cu_inj_nn-0.0.20.tar.gz saved to /tmp/tmpvoodm9hi/lume_lcls_cu_inj_nn-0.0.20.tar.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/thakur12/.conda/envs/lume-lcls-cu-inj-nn-torch/bin/python', '-m', 'pip', 'install', '--no-deps', '-v', '/tmp/tmpvoodm9hi/lume_lcls_cu_inj_nn-0.0.20.tar.gz']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command python setup.py egg_info\n",
      "  running egg_info\n",
      "  creating /tmp/pip-pip-egg-info-uz9iv9bc/lume_lcls_cu_inj_nn.egg-info\n",
      "  writing /tmp/pip-pip-egg-info-uz9iv9bc/lume_lcls_cu_inj_nn.egg-info/PKG-INFO\n",
      "  writing dependency_links to /tmp/pip-pip-egg-info-uz9iv9bc/lume_lcls_cu_inj_nn.egg-info/dependency_links.txt\n",
      "  writing entry points to /tmp/pip-pip-egg-info-uz9iv9bc/lume_lcls_cu_inj_nn.egg-info/entry_points.txt\n",
      "  writing requirements to /tmp/pip-pip-egg-info-uz9iv9bc/lume_lcls_cu_inj_nn.egg-info/requires.txt\n",
      "  writing top-level names to /tmp/pip-pip-egg-info-uz9iv9bc/lume_lcls_cu_inj_nn.egg-info/top_level.txt\n",
      "  writing manifest file '/tmp/pip-pip-egg-info-uz9iv9bc/lume_lcls_cu_inj_nn.egg-info/SOURCES.txt'\n",
      "  reading manifest file '/tmp/pip-pip-egg-info-uz9iv9bc/lume_lcls_cu_inj_nn.egg-info/SOURCES.txt'\n",
      "  reading manifest template 'MANIFEST.in'\n",
      "  warning: no files found matching 'LICENSE'\n",
      "  writing manifest file '/tmp/pip-pip-egg-info-uz9iv9bc/lume_lcls_cu_inj_nn.egg-info/SOURCES.txt'\n",
      "  Running command python setup.py bdist_wheel\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build/lib\n",
      "  creating build/lib/lume_lcls_cu_inj_nn\n",
      "  copying lume_lcls_cu_inj_nn/model.py -> build/lib/lume_lcls_cu_inj_nn\n",
      "  copying lume_lcls_cu_inj_nn/__init__.py -> build/lib/lume_lcls_cu_inj_nn\n",
      "  copying lume_lcls_cu_inj_nn/_version.py -> build/lib/lume_lcls_cu_inj_nn\n",
      "  copying lume_lcls_cu_inj_nn/flow.py -> build/lib/lume_lcls_cu_inj_nn\n",
      "  copying lume_lcls_cu_inj_nn/_image.py -> build/lib/lume_lcls_cu_inj_nn\n",
      "  creating build/lib/lume_lcls_cu_inj_nn/files\n",
      "  copying lume_lcls_cu_inj_nn/files/__init__.py -> build/lib/lume_lcls_cu_inj_nn/files\n",
      "  creating build/lib/lume_lcls_cu_inj_nn/tests\n",
      "  copying lume_lcls_cu_inj_nn/tests/__init__.py -> build/lib/lume_lcls_cu_inj_nn/tests\n",
      "  copying lume_lcls_cu_inj_nn/tests/test_flow.py -> build/lib/lume_lcls_cu_inj_nn/tests\n",
      "  running egg_info\n",
      "  writing lume_lcls_cu_inj_nn.egg-info/PKG-INFO\n",
      "  writing dependency_links to lume_lcls_cu_inj_nn.egg-info/dependency_links.txt\n",
      "  writing entry points to lume_lcls_cu_inj_nn.egg-info/entry_points.txt\n",
      "  writing requirements to lume_lcls_cu_inj_nn.egg-info/requires.txt\n",
      "  writing top-level names to lume_lcls_cu_inj_nn.egg-info/top_level.txt\n",
      "  reading manifest file 'lume_lcls_cu_inj_nn.egg-info/SOURCES.txt'\n",
      "  reading manifest template 'MANIFEST.in'\n",
      "  warning: no files found matching 'LICENSE'\n",
      "  writing manifest file 'lume_lcls_cu_inj_nn.egg-info/SOURCES.txt'\n",
      "  copying lume_lcls_cu_inj_nn/files/cu_inj_impact.csv -> build/lib/lume_lcls_cu_inj_nn/files\n",
      "  copying lume_lcls_cu_inj_nn/files/epics_config.yml -> build/lib/lume_lcls_cu_inj_nn/files\n",
      "  copying lume_lcls_cu_inj_nn/files/model_1b_AS_f_xy.h5 -> build/lib/lume_lcls_cu_inj_nn/files\n",
      "  copying lume_lcls_cu_inj_nn/files/variables.yml -> build/lib/lume_lcls_cu_inj_nn/files\n",
      "  UPDATING build/lib/lume_lcls_cu_inj_nn/_version.py\n",
      "  set build/lib/lume_lcls_cu_inj_nn/_version.py to '0.0.20'\n",
      "  /home/thakur12/.conda/envs/lume-lcls-cu-inj-nn-torch/lib/python3.9/site-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
      "  !!\n",
      "\n",
      "          ********************************************************************************\n",
      "          Please avoid running ``setup.py`` directly.\n",
      "          Instead, use pypa/build, pypa/installer or other\n",
      "          standards-based tools.\n",
      "\n",
      "          See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
      "          ********************************************************************************\n",
      "\n",
      "  !!\n",
      "    self.initialize_options()\n",
      "  installing to build/bdist.linux-x86_64/wheel\n",
      "  running install\n",
      "  running install_lib\n",
      "  creating build/bdist.linux-x86_64\n",
      "  creating build/bdist.linux-x86_64/wheel\n",
      "  creating build/bdist.linux-x86_64/wheel/lume_lcls_cu_inj_nn\n",
      "  creating build/bdist.linux-x86_64/wheel/lume_lcls_cu_inj_nn/files\n",
      "  copying build/lib/lume_lcls_cu_inj_nn/files/__init__.py -> build/bdist.linux-x86_64/wheel/lume_lcls_cu_inj_nn/files\n",
      "  copying build/lib/lume_lcls_cu_inj_nn/files/cu_inj_impact.csv -> build/bdist.linux-x86_64/wheel/lume_lcls_cu_inj_nn/files\n",
      "  copying build/lib/lume_lcls_cu_inj_nn/files/variables.yml -> build/bdist.linux-x86_64/wheel/lume_lcls_cu_inj_nn/files\n",
      "  copying build/lib/lume_lcls_cu_inj_nn/files/epics_config.yml -> build/bdist.linux-x86_64/wheel/lume_lcls_cu_inj_nn/files\n",
      "  copying build/lib/lume_lcls_cu_inj_nn/files/model_1b_AS_f_xy.h5 -> build/bdist.linux-x86_64/wheel/lume_lcls_cu_inj_nn/files\n",
      "  copying build/lib/lume_lcls_cu_inj_nn/model.py -> build/bdist.linux-x86_64/wheel/lume_lcls_cu_inj_nn\n",
      "  copying build/lib/lume_lcls_cu_inj_nn/__init__.py -> build/bdist.linux-x86_64/wheel/lume_lcls_cu_inj_nn\n",
      "  creating build/bdist.linux-x86_64/wheel/lume_lcls_cu_inj_nn/tests\n",
      "  copying build/lib/lume_lcls_cu_inj_nn/tests/__init__.py -> build/bdist.linux-x86_64/wheel/lume_lcls_cu_inj_nn/tests\n",
      "  copying build/lib/lume_lcls_cu_inj_nn/tests/test_flow.py -> build/bdist.linux-x86_64/wheel/lume_lcls_cu_inj_nn/tests\n",
      "  copying build/lib/lume_lcls_cu_inj_nn/_version.py -> build/bdist.linux-x86_64/wheel/lume_lcls_cu_inj_nn\n",
      "  copying build/lib/lume_lcls_cu_inj_nn/flow.py -> build/bdist.linux-x86_64/wheel/lume_lcls_cu_inj_nn\n",
      "  copying build/lib/lume_lcls_cu_inj_nn/_image.py -> build/bdist.linux-x86_64/wheel/lume_lcls_cu_inj_nn\n",
      "  running install_egg_info\n",
      "  Copying lume_lcls_cu_inj_nn.egg-info to build/bdist.linux-x86_64/wheel/lume_lcls_cu_inj_nn-0.0.20-py3.9.egg-info\n",
      "  running install_scripts\n",
      "  creating build/bdist.linux-x86_64/wheel/lume_lcls_cu_inj_nn-0.0.20.dist-info/WHEEL\n",
      "  creating '/tmp/pip-wheel-5z098g41/lume_lcls_cu_inj_nn-0.0.20-py3-none-any.whl' and adding 'build/bdist.linux-x86_64/wheel' to it\n",
      "  adding 'lume_lcls_cu_inj_nn/__init__.py'\n",
      "  adding 'lume_lcls_cu_inj_nn/_image.py'\n",
      "  adding 'lume_lcls_cu_inj_nn/_version.py'\n",
      "  adding 'lume_lcls_cu_inj_nn/flow.py'\n",
      "  adding 'lume_lcls_cu_inj_nn/model.py'\n",
      "  adding 'lume_lcls_cu_inj_nn/files/__init__.py'\n",
      "  adding 'lume_lcls_cu_inj_nn/files/cu_inj_impact.csv'\n",
      "  adding 'lume_lcls_cu_inj_nn/files/epics_config.yml'\n",
      "  adding 'lume_lcls_cu_inj_nn/files/model_1b_AS_f_xy.h5'\n",
      "  adding 'lume_lcls_cu_inj_nn/files/variables.yml'\n",
      "  adding 'lume_lcls_cu_inj_nn/tests/__init__.py'\n",
      "  adding 'lume_lcls_cu_inj_nn/tests/test_flow.py'\n",
      "  adding 'lume_lcls_cu_inj_nn-0.0.20.dist-info/METADATA'\n",
      "  adding 'lume_lcls_cu_inj_nn-0.0.20.dist-info/WHEEL'\n",
      "  adding 'lume_lcls_cu_inj_nn-0.0.20.dist-info/entry_points.txt'\n",
      "  adding 'lume_lcls_cu_inj_nn-0.0.20.dist-info/top_level.txt'\n",
      "  adding 'lume_lcls_cu_inj_nn-0.0.20.dist-info/RECORD'\n",
      "  removing build/bdist.linux-x86_64/wheel\n",
      "INFO:lume_services.environment.solver:Dependency installation complete\n",
      "2023-07-31 17:49:13.962700: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "INFO:lume_services.services.models.db.db:ModelDB selecting: SELECT deployment.deployment_id, deployment.version, deployment.deploy_date, deployment.package_import_name, deployment.asset_dir, deployment.source, deployment.sha256, deployment.image, deployment.is_live, deployment.model_id \n",
      "FROM deployment \n",
      "WHERE deployment.model_id = :model_id_1 AND deployment.version = :version_1\n",
      "INFO:lume_services.services.models.db.db:ModelDB inserting: INSERT INTO deployment (version, package_import_name, asset_dir, source, sha256, image, is_live, model_id) VALUES (:version, :package_import_name, :asset_dir, :source, :sha256, :image, :is_live, :model_id)\n",
      "INFO:lume_services.services.models.db.db:Sucessfully executed: INSERT INTO deployment (version, package_import_name, asset_dir, source, sha256, image, is_live, model_id) VALUES (:version, :package_import_name, :asset_dir, :source, :sha256, :image, :is_live, :model_id)\n",
      "INFO:lume_services.services.models.db.db:ModelDB selecting: SELECT flow.flow_id, flow.flow_name, flow.project_name, flow.deployment_id \n",
      "FROM flow \n",
      "WHERE flow.deployment_id = :deployment_id_1\n",
      "INFO:lume_services.services.scheduling.backends.server:Flow run config is not empty. Clearing existing labels and assigning                     new.\n",
      "/home/thakur12/.conda/envs/lume-lcls-cu-inj-nn-torch/lib/python3.9/site-packages/prefect/core/flow.py:1726: UserWarning: No result handler was specified on your Flow. Cloud features such as input caching and resuming task runs from failure may not work properly.\n",
      "  registered_flow = client.register(\n",
      "INFO:lume_services.services.models.db.db:ModelDB inserting: INSERT INTO flow (flow_id, flow_name, project_name, deployment_id) VALUES (:flow_id, :flow_name, :project_name, :deployment_id)\n",
      "INFO:lume_services.services.models.db.db:Sucessfully executed: INSERT INTO flow (flow_id, flow_name, project_name, deployment_id) VALUES (:flow_id, :flow_name, :project_name, :deployment_id)\n",
      "INFO:lume_services.models.model:Loading deployment 1\n",
      "INFO:lume_services.models.model:Loading deployment 1\n",
      "INFO:lume_services.services.models.db.db:ModelDB selecting: SELECT deployment.deployment_id, deployment.version, deployment.deploy_date, deployment.package_import_name, deployment.asset_dir, deployment.source, deployment.sha256, deployment.image, deployment.is_live, deployment.model_id \n",
      "FROM deployment \n",
      "WHERE deployment.model_id = :model_id_1 AND deployment.deployment_id = :deployment_id_1\n",
      "INFO:lume_services.models.model:Deployment loaded.\n",
      "INFO:lume_services.services.models.db.db:ModelDB selecting: SELECT flow.flow_id, flow.flow_name, flow.project_name, flow.deployment_id \n",
      "FROM flow \n",
      "WHERE flow.deployment_id = :deployment_id_1\n",
      "INFO:lume_services.services.models.db.db:ModelDB selecting: SELECT project.project_name, project.description \n",
      "FROM project \n",
      "WHERE project.project_name = :project_name_1\n",
      "INFO:lume_services.services.models.db.db:ModelDB selecting: SELECT flow_of_flows._id, flow_of_flows.parent_flow_id, flow_of_flows.flow_id, flow_of_flows.position \n",
      "FROM flow_of_flows \n",
      "WHERE flow_of_flows.parent_flow_id = :parent_flow_id_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flow URL: http://localhost:8080/default/flow/b23fee9c-0d52-4f11-9813-475c1fb70c8a\n",
      " └── ID: a4712eac-e30a-4abc-b6e9-56e0c706be8e\n",
      " └── Project: gpu-box-new\n",
      " └── Labels: ['lume-services']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(metadata=Model(                     model_id=1,                     created=datetime.datetime(2023, 8, 1, 0, 47, 35),                     author='Aman Singh Thakur'),                     laboratory='slac',                     facility='lcls',                     beampath='cu',                     description='lcls-cu-inj-nn'                 ), deployment=Deployment(metadata=Deployment(                 deployment_id=1,                 model_id=1,                 version='0.0.20',                 deploy_date=datetime.datetime(2023, 8, 1, 0, 49, 15)),                 asset_dir=None,                 source='https://github.com/singh96aman/lume-lcls-cu-inj-nn/releases/download/v0.0.20/lume_lcls_cu_inj_nn-0.0.20.tar.gz',                 sha256='ddfa081fef58a639fe132ef02327a3eb98556e9bea4478ce38c211c414b60153',                 image='scr.svc.stanford.edu/aman96/lume-lcls-cu-inj-nn:v0.0.20',                 is_live=True                 package_import_name='lume_lcls_cu_inj_nn'                 ), project=Project(metadata=Project(                 project_name='gpu-box-new',                 description='my_description',                 )), flow=Flow(name='lume-lcls-cu-inj-nn', flow_id='a4712eac-e30a-4abc-b6e9-56e0c706be8e', project_name='gpu-box-new', prefect_flow=<Flow: name=\"lume-lcls-cu-inj-nn\">, parameters=None, mapped_parameters=None, task_slugs=None, labels=['lume-services'], image='scr.svc.stanford.edu/aman96/lume-lcls-cu-inj-nn:v0.0.20'), model_type=<class 'lume_lcls_cu_inj_nn.model.LCLSCuInjNN'>), results=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#source_path = \"https://github.com/jacquelinegarrahan/lume-lcls-cu-inj-nn/releases/download/v0.0.12/lume_lcls_cu_inj_nn-0.0.12.tar.gz\"\n",
    "\n",
    "source_path = \"https://github.com/singh96aman/lume-lcls-cu-inj-nn/releases/download/v0.0.20/lume_lcls_cu_inj_nn-0.0.20.tar.gz\"\n",
    "\n",
    "# populates local channel\n",
    "model.store_deployment(source_path, project_name=\"gpu-box-new\")\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690f0c1c",
   "metadata": {},
   "source": [
    "## Run the Prefect workflow directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "514e0aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-31 17:49:22-0700] INFO - prefect.FlowRunner | Beginning Flow run for 'lume-lcls-cu-inj-nn'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prefect.FlowRunner:Beginning Flow run for 'lume-lcls-cu-inj-nn'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-31 17:49:22-0700] INFO - prefect.TaskRunner | Task 'SOL1:solenoid_field_scale': Starting task run...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prefect.TaskRunner:Task 'SOL1:solenoid_field_scale': Starting task run...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-31 17:49:23-0700] INFO - prefect.TaskRunner | Task 'SOL1:solenoid_field_scale': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prefect.TaskRunner:Task 'SOL1:solenoid_field_scale': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-31 17:49:23-0700] INFO - prefect.TaskRunner | Task 'distgen:r_dist:sigma_xy:value': Starting task run...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prefect.TaskRunner:Task 'distgen:r_dist:sigma_xy:value': Starting task run...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-31 17:49:23-0700] INFO - prefect.TaskRunner | Task 'distgen:r_dist:sigma_xy:value': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prefect.TaskRunner:Task 'distgen:r_dist:sigma_xy:value': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-31 17:49:23-0700] INFO - prefect.TaskRunner | Task 'configure_lume_services': Starting task run...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prefect.TaskRunner:Task 'configure_lume_services': Starting task run...\n",
      "INFO:lume_services.config:Configuring LUME-services environment...\n",
      "INFO:lume_services.config:Environment configured.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-31 17:49:23-0700] INFO - prefect.TaskRunner | Task 'configure_lume_services': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prefect.TaskRunner:Task 'configure_lume_services': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-31 17:49:23-0700] INFO - prefect.TaskRunner | Task 'CQ01:b1_gradient': Starting task run...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prefect.TaskRunner:Task 'CQ01:b1_gradient': Starting task run...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-31 17:49:23-0700] INFO - prefect.TaskRunner | Task 'CQ01:b1_gradient': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prefect.TaskRunner:Task 'CQ01:b1_gradient': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-31 17:49:23-0700] INFO - prefect.TaskRunner | Task 'L0A_scale:voltage': Starting task run...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prefect.TaskRunner:Task 'L0A_scale:voltage': Starting task run...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-31 17:49:23-0700] INFO - prefect.TaskRunner | Task 'L0A_scale:voltage': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prefect.TaskRunner:Task 'L0A_scale:voltage': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-31 17:49:23-0700] INFO - prefect.TaskRunner | Task 'distgen:t_dist:length:value': Starting task run...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prefect.TaskRunner:Task 'distgen:t_dist:length:value': Starting task run...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-31 17:49:23-0700] INFO - prefect.TaskRunner | Task 'distgen:t_dist:length:value': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prefect.TaskRunner:Task 'distgen:t_dist:length:value': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-31 17:49:23-0700] INFO - prefect.TaskRunner | Task 'SQ01:b1_gradient': Starting task run...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prefect.TaskRunner:Task 'SQ01:b1_gradient': Starting task run...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-31 17:49:23-0700] INFO - prefect.TaskRunner | Task 'SQ01:b1_gradient': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prefect.TaskRunner:Task 'SQ01:b1_gradient': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-31 17:49:23-0700] INFO - prefect.TaskRunner | Task 'end_mean_z': Starting task run...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prefect.TaskRunner:Task 'end_mean_z': Starting task run...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-31 17:49:23-0700] INFO - prefect.TaskRunner | Task 'end_mean_z': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prefect.TaskRunner:Task 'end_mean_z': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-31 17:49:23-0700] INFO - prefect.TaskRunner | Task 'check_local_execution': Starting task run...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prefect.TaskRunner:Task 'check_local_execution': Starting task run...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-31 17:49:23-0700] INFO - prefect.TaskRunner | Task 'check_local_execution': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prefect.TaskRunner:Task 'check_local_execution': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-31 17:49:23-0700] INFO - prefect.TaskRunner | Task 'distgen:total_charge:value': Starting task run...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prefect.TaskRunner:Task 'distgen:total_charge:value': Starting task run...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-31 17:49:23-0700] INFO - prefect.TaskRunner | Task 'distgen:total_charge:value': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prefect.TaskRunner:Task 'distgen:total_charge:value': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-31 17:49:23-0700] INFO - prefect.TaskRunner | Task 'L0A_phase:dtheta0_deg': Starting task run...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prefect.TaskRunner:Task 'L0A_phase:dtheta0_deg': Starting task run...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-31 17:49:23-0700] INFO - prefect.TaskRunner | Task 'L0A_phase:dtheta0_deg': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prefect.TaskRunner:Task 'L0A_phase:dtheta0_deg': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-31 17:49:23-0700] INFO - prefect.TaskRunner | Task 'List': Starting task run...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prefect.TaskRunner:Task 'List': Starting task run...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-31 17:49:23-0700] INFO - prefect.TaskRunner | Task 'List': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prefect.TaskRunner:Task 'List': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-31 17:49:23-0700] INFO - prefect.TaskRunner | Task 'case(False)': Starting task run...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prefect.TaskRunner:Task 'case(False)': Starting task run...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-31 17:49:23-0700] INFO - prefect.TaskRunner | Task 'case(False)': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prefect.TaskRunner:Task 'case(False)': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-31 17:49:23-0700] INFO - prefect.TaskRunner | Task 'Dict': Starting task run...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prefect.TaskRunner:Task 'Dict': Starting task run...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-31 17:49:23-0700] INFO - prefect.TaskRunner | Task 'Dict': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prefect.TaskRunner:Task 'Dict': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-31 17:49:23-0700] INFO - prefect.TaskRunner | Task 'prepare_lume_model_variables': Starting task run...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prefect.TaskRunner:Task 'prepare_lume_model_variables': Starting task run...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-31 17:49:23-0700] INFO - prefect.TaskRunner | Task 'prepare_lume_model_variables': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prefect.TaskRunner:Task 'prepare_lume_model_variables': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-31 17:49:23-0700] INFO - prefect.TaskRunner | Task 'preprocessing_task': Starting task run...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prefect.TaskRunner:Task 'preprocessing_task': Starting task run...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-31 17:49:23-0700] INFO - prefect.TaskRunner | Task 'preprocessing_task': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prefect.TaskRunner:Task 'preprocessing_task': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-31 17:49:23-0700] INFO - prefect.TaskRunner | Task 'evaluate': Starting task run...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prefect.TaskRunner:Task 'evaluate': Starting task run...\n",
      "2023-07-31 17:49:23.284036: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-31 17:49:23.284255: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-31 17:49:23.300648: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-31 17:49:23.300890: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysf"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-31 17:49:24-0700] INFO - prefect.TaskRunner | [array([[ 1.37666653e-01,  1.23746245e+01,  4.00544158e-05,\n",
      "         8.74263114e-02,  3.52380952e-03,  3.52380952e-03,\n",
      "        -8.89970000e+00,  7.00000000e+13,  4.61470020e+00]])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "s-bus-pci#L344-L355\n",
      "2023-07-31 17:49:23.301069: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-31 17:49:23.301241: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-31 17:49:23.429654: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-31 17:49:23.429861: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-31 17:49:23.430039: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-31 17:49:23.430207: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-31 17:49:23.430373: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-31 17:49:23.430542: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-31 17:49:23.913943: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-31 17:49:23.914169: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-31 17:49:23.914354: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-31 17:49:23.914529: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-31 17:49:23.914700: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-31 17:49:23.914843: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46714 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:2a:00.0, compute capability: 8.6\n",
      "2023-07-31 17:49:23.915178: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-31 17:49:23.915318: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 46669 MB memory:  -> device: 1, name: NVIDIA RTX A6000, pci bus id: 0000:61:00.0, compute capability: 8.6\n",
      "INFO:prefect.TaskRunner:[array([[ 1.37666653e-01,  1.23746245e+01,  4.00544158e-05,\n",
      "         8.74263114e-02,  3.52380952e-03,  3.52380952e-03,\n",
      "        -8.89970000e+00,  7.00000000e+13,  4.61470020e+00]])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0sRunner | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-31 17:49:25.200743: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "1/1 [==============================] - ETA: 0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 725ms/step \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 725ms/step\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-31 17:49:25-0700] INFO - prefect.TaskRunner | Task 'evaluate': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prefect.TaskRunner:Task 'evaluate': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-31 17:49:25-0700] INFO - prefect.TaskRunner | Task 'format_result': Starting task run...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prefect.TaskRunner:Task 'format_result': Starting task run...\n",
      "WARNING:lume_services.results.generic:No project_name passed to result\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-31 17:49:25-0700] INFO - prefect.TaskRunner | Task 'format_result': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prefect.TaskRunner:Task 'format_result': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-31 17:49:25-0700] INFO - prefect.TaskRunner | Task 'save_db_result': Starting task run...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prefect.TaskRunner:Task 'save_db_result': Starting task run...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-31 17:49:25-0700] INFO - prefect.TaskRunner | Task 'save_db_result': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prefect.TaskRunner:Task 'save_db_result': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-31 17:49:25-0700] INFO - prefect.FlowRunner | Flow run SUCCESS: all reference tasks succeeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prefect.FlowRunner:Flow run SUCCESS: all reference tasks succeeded\n"
     ]
    }
   ],
   "source": [
    "flow_run = model.deployment.flow.prefect_flow.run(**{\n",
    "                        \"distgen:r_dist:sigma_xy:value\": 0.4130, \n",
    "                        \"distgen:total_charge:value\": 250.0, \n",
    "                        \"distgen:t_dist:length:value\":7.499772441611215, \n",
    "                        \"SOL1:solenoid_field_scale\": 0.17, \n",
    "                        \"CQ01:b1_gradient\":-0.0074,\n",
    "                        \"SQ01:b1_gradient\": -0.0074,\n",
    "                        \"L0A_phase:dtheta0_deg\": -8.8997,\n",
    "                        \"L0A_scale:voltage\": 70000000.0,\n",
    "                        \"distgen:t_dist:length:value\": 7.499772441611215,\n",
    "                        \"end_mean_z\": 4.6147002\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc08d87",
   "metadata": {},
   "source": [
    "## Run the workflow inside the service cluster\n",
    "We can use the model interface to directly deploy workflows. When sourcing our environment (`docs/examples/demo.env`), we defined a mount point for the file system using the alias `/lume-services/data`. Let's kick off this workflow and save the file output to that directory. \n",
    "After running the next cell, you'll be able to see the running container in your docker desktop and examine the flow using the Prefect UI at http://localhost:8080/default?flows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90a5769f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.run(\n",
    "    parameters = {\n",
    "                        \"distgen:r_dist:sigma_xy:value\": 0.4130, \n",
    "                        \"distgen:total_charge:value\": 250.0, \n",
    "                        \"distgen:t_dist:length:value\":7.499772441611215, \n",
    "                        \"SOL1:solenoid_field_scale\": 0.17, \n",
    "                        \"CQ01:b1_gradient\":-0.0074,\n",
    "                        \"SQ01:b1_gradient\": -0.0074,\n",
    "                        \"L0A_phase:dtheta0_deg\": -8.8997,\n",
    "                        \"L0A_scale:voltage\": 70000000.0,\n",
    "                        \"distgen:t_dist:length:value\": 7.499772441611215,\n",
    "                        \"end_mean_z\": 4.6147002\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49ca124d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Flow(name='lume-lcls-cu-inj-nn', flow_id='a4712eac-e30a-4abc-b6e9-56e0c706be8e', project_name='gpu-box-new', prefect_flow=None, parameters=None, mapped_parameters=None, task_slugs=None, labels=['lume-services'], image='scr.svc.stanford.edu/aman96/lume-lcls-cu-inj-nn:v0.0.20')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.deployment.flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409851f9",
   "metadata": {},
   "source": [
    "# Get results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ffa8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.get_results()\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b388faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = model.get_results_df()\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f26a31",
   "metadata": {},
   "source": [
    "## Load model using model id\n",
    "Once your model has been registered, you can use the `Model` api object to interact with your model without running the above registration steps. Let's load a new model object using the model_id we registered above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6ef8e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lume_services.services.models.db.db:ModelDB selecting: SELECT model.model_id, model.created, model.author, model.laboratory, model.facility, model.beampath, model.description \n",
      "FROM model \n",
      "WHERE model.model_id = :model_id_1\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload \n",
    "import lume_services\n",
    "reload(lume_services.models)\n",
    "from lume_services.models import Model\n",
    "\n",
    "#model_id = model.metadata.model_id\n",
    "loaded_model = Model(model_id=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7a15668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(                     model_id=1,                     created=datetime.datetime(2023, 8, 1, 0, 47, 35),                     author='Aman Singh Thakur'),                     laboratory='slac',                     facility='lcls',                     beampath='cu',                     description='lcls-cu-inj-nn'                 )"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ca3ce4",
   "metadata": {},
   "source": [
    "## Load existing model object\n",
    "Loading a model using the load_deployment method without passing a deployment_id will load the latest deployment registered for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "040bb4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lume_services.models.model:Loading latest deployment.\n",
      "INFO:lume_services.services.models.db.db:ModelDB selecting: SELECT deployment.deployment_id, deployment.version, deployment.deploy_date, deployment.package_import_name, deployment.asset_dir, deployment.source, deployment.sha256, deployment.image, deployment.is_live, deployment.model_id \n",
      "FROM deployment \n",
      "WHERE deployment.model_id = :model_id_1 ORDER BY deployment.deploy_date DESC\n",
      "INFO:lume_services.services.models.db.db:ModelDB selecting: SELECT flow.flow_id, flow.flow_name, flow.project_name, flow.deployment_id \n",
      "FROM flow \n",
      "WHERE flow.deployment_id = :deployment_id_1\n",
      "INFO:lume_services.services.models.db.db:ModelDB selecting: SELECT project.project_name, project.description \n",
      "FROM project \n",
      "WHERE project.project_name = :project_name_1\n",
      "INFO:lume_services.services.models.db.db:ModelDB selecting: SELECT flow_of_flows._id, flow_of_flows.parent_flow_id, flow_of_flows.flow_id, flow_of_flows.position \n",
      "FROM flow_of_flows \n",
      "WHERE flow_of_flows.parent_flow_id = :parent_flow_id_1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Deployment(metadata=Deployment(                 deployment_id=1,                 model_id=1,                 version='0.0.20',                 deploy_date=datetime.datetime(2023, 8, 1, 0, 49, 15)),                 asset_dir=None,                 source='https://github.com/singh96aman/lume-lcls-cu-inj-nn/releases/download/v0.0.20/lume_lcls_cu_inj_nn-0.0.20.tar.gz',                 sha256='ddfa081fef58a639fe132ef02327a3eb98556e9bea4478ce38c211c414b60153',                 image='scr.svc.stanford.edu/aman96/lume-lcls-cu-inj-nn:v0.0.20',                 is_live=True                 package_import_name='lume_lcls_cu_inj_nn'                 ), project=Project(metadata=Project(                 project_name='gpu-box-new',                 description='my_description',                 )), flow=Flow(name='lume-lcls-cu-inj-nn', flow_id='a4712eac-e30a-4abc-b6e9-56e0c706be8e', project_name='gpu-box-new', prefect_flow=None, parameters=None, mapped_parameters=None, task_slugs=None, labels=['lume-services'], image='scr.svc.stanford.edu/aman96/lume-lcls-cu-inj-nn:v0.0.20'), model_type=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.load_deployment()\n",
    "loaded_model.deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ff1d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = loaded_model.run_and_return(\n",
    "    parameters={\n",
    "                        \"distgen:r_dist:sigma_xy:value\": 0.4130, \n",
    "                        \"distgen:total_charge:value\": 250.0, \n",
    "                        \"distgen:t_dist:length:value\":7.499772441611215, \n",
    "                        \"SOL1:solenoid_field_scale\": 0.17, \n",
    "                        \"CQ01:b1_gradient\":-0.0074,\n",
    "                        \"SQ01:b1_gradient\": -0.0074,\n",
    "                        \"L0A_phase:dtheta0_deg\": -8.8997,\n",
    "                        \"L0A_scale:voltage\": 70000000.0,\n",
    "                        \"distgen:t_dist:length:value\": 7.499772441611215,\n",
    "                        \"end_mean_z\": 4.6147002\n",
    "    },\n",
    "    task_name=\"save_db_result\" # Want to get the result from the save_db_result task\n",
    ")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c25a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = loaded_model.get_results_df()\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0a3f6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "7b1aa5d32c5360a08f3d071b8537e8759b8901de3eea112666c46651e79793b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
